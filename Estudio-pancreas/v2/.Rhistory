summary(pr)
pr$a
x[c(61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80), ]
pr$a
x[c(61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80), c(37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52)]
pr$a
dataset<-read.csv(file = "/home/ogreyesp/Desktop/emotions.csv", sep = ",", header = F)
View(dataset)
dataset<-dataset[,c(73:78)]
as.logical(dataset)
matrix(dataset)
matrix(dataset)
?matrix
?proximus
?matrix
m<-matrix(nrow = 593, ncol = 6)
dataset
data.matrix(dataset)
proximus(data.matrix(dataset), max.radius = 8)
m<-data.matrix(dataset)
class(m)
apply(m, 2, as.logical)
m<-apply(m, 2, as.logical)
pr<-proximus(m, max.radius = 8)
pr
summary(pr)
pr<-proximus(m, max.radius = 5)
summary(pr)
pr<-proximus(m, max.radius = 20)
summary(pr)
pr<-proximus(m, max.radius = 8)
pr$a
m[c(1,4,6,10),3]
m[c(5,15,60,71,91), c(4,5)]
m[c(5,15,60,71,91,125,153,158,187,200,208,216,219,253,256,295,300,301,303), c(4,5)]
m[c(2,3,7,8,9,13,16,19,21,24,25,28,31,33,34,35,39,40,42),c(1,6)]
cor(m, method = c("pearson"))
x = c(1,  1,  0,  0,  1,  0,  1,  1,  1)
y = c(1,  1,  0,  0,  0,  0,  1,  1,  1)
cor(x,y)
sqrt(chisq.test(table(m[,1],m[2]), correct=FALSE)$statistic/length(593))
sqrt(chisq.test(table(m[,1],m[,2]), correct=FALSE)$statistic/length(593))
sqrt(chisq.test(table(m[,4],m[,5]), correct=FALSE)$statistic/length(593))
sqrt(chisq.test(table(m[,1],m[,6]), correct=FALSE)$statistic/length(593))
install.packages("GenomicRanges")
source("https://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite("GenomicRanges")
library(GenomicRanges)
phicoef(m[,1], m[,6])
phicoef(m[,4], m[,5])
strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47")
strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", sep="\t")
?strsplit
strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t")
unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))
sum(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t")))
sum(as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))))
73.21/1758
73.21/1758
sum(as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))))
sum(as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))))
c<-as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t")))
sum(c)/length(c)
73.21/33.80865
remove(list = ls())
library(cba)
library(caret)
library(pROC)
library(doMC)
registerDoMC(cores = 2)
source("EvaluationMeasure.R")
nlabels <- c("emotions"=6)
nameDataset <- "emotions"
hammingMean <- c()
#For each random fold
for(fold in 1:5){
cat("Fold:",fold,"\n")
dataset <- read.csv(file = paste0("datasets/", nameDataset, "-train", fold,".csv"), sep = ",", header = F)
cols <- ncol(dataset)
nFeatures <- cols - nlabels[nameDataset]
#Converting the label columns in logical factors
dataset[, c((nFeatures+1):cols)] <- apply(dataset[, c((nFeatures+1):cols)], 2, as.logical)
#Executing the Proximus algorithms
labelSpace <- data.matrix(dataset[, c((nFeatures+1):cols)])
labelSpace <- apply(labelSpace, 2, as.logical)
# Compute the cardinality of the training set
cardinality <- mean(apply(labelSpace, 1, sum))
pr <- proximus(labelSpace, max.radius= ceiling(cardinality))
summary(pr)
summaryPatterns <- summary(pr)$pattern
numberCluster <- length(pr$a)
#Creating the new dataset for multi-class prediction
multiclassDataset <- dataset[ , c(1:nFeatures)]
multiclassDataset <- cbind(multiclassDataset, Class= rep("C1", nrow(multiclassDataset)))
levels(multiclassDataset$Class) <- paste0("C", c(1:numberCluster))
numberInstances <- nrow(multiclassDataset)
caseWeights <- rep(1, numberInstances)
for(c in 1:numberCluster){
#Creating class c
cat("Index:", c, " Labels:", pr$a[[c]]$y, " ", "instances:" , length(pr$a[[c]]$x), "\n")
multiclassDataset[pr$a[[c]]$x, "Class"] <- as.factor(paste0("C", c))
# Computing the case weights for handling imbalanced problems
caseWeights[pr$a[[c]]$x] <- numberInstances/(numberCluster* length(pr$a[[c]]$x))
}
# Using the new dataset as training set
fitControl <- trainControl(method="repeatedcv", number = 10, repeats = 1, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = multiClassSummary, verboseIter = FALSE)
modelFit <- train(Class ~ ., data = multiclassDataset,
method="C5.0",  # implementation of random forest that supports case weights
metric = "AUC",
maximize = TRUE,
trControl = fitControl, tuneLength = 5, weights = caseWeights, preProcess = c("nzv","zv","center", "scale"))
# Proccess for the creation of binary classifiers
binaryClassifiers <- matrix(list(list()),  numberCluster, nlabels[nameDataset])
BinaryFitControl <- trainControl(method="repeatedcv", number = 10, repeats = 1, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
for(indexCluster in 1:numberCluster){
if(summaryPatterns[indexCluster, "Radius"] > 0){
# subdataset with all labels in the cluster
subdataset <- dataset[pr$a[[indexCluster]]$x,]
# For each label
for(indexLabel in (nFeatures+1):(nFeatures+nlabels[nameDataset])){
values <- unique(subdataset[, indexLabel])
if(length(values) == 2){
# If there are two values, then train a classifier and predict with this classifier
binarySubdataset <- subdataset[, c(1:nFeatures, indexLabel)]
# Computing the case weights for handling imbalanced problems
numberBinaryInstances <- nrow(binarySubdataset)
trueInstances <- sum(binarySubdataset[, nFeatures+1])
negativeInstances <- numberBinaryInstances - trueInstances
binaryCaseWeights <- rep(1, numberBinaryInstances)
binaryCaseWeights[binarySubdataset[, nFeatures+1]==TRUE] <- numberBinaryInstances/(2 * trueInstances)
binaryCaseWeights[binarySubdataset[, nFeatures+1]==FALSE] <- numberBinaryInstances/(2 * negativeInstances)
#Converting the last column to factor. Los valores True y False no se pueden dejar porque dan error.
binarySubdataset[, nFeatures+1] <- as.factor(binarySubdataset[, nFeatures+1])
levels(binarySubdataset[, nFeatures+1]) <- make.names(levels(factor(binarySubdataset[, nFeatures+1])))
binaryClassifiers[indexCluster, indexLabel-nFeatures][[1]] <- train(as.formula(paste0(colnames(binarySubdataset)[nFeatures+1], "~ .")), data = binarySubdataset,
method="rf",  # implementation of random forest that supports case weights
metric = "ROC",
maximize = TRUE,
trControl = BinaryFitControl,
tuneLength = 5, weights = binaryCaseWeights, preProcess = c("nzv","zv","center", "scale"))
}
}
}
}
testDataset <-read.csv(file = paste0("datasets/", nameDataset, "-test", fold,".csv"), sep = ",", header = F)
testDataset[, c((nFeatures+1):cols)] <- apply(testDataset[, c((nFeatures+1):cols)], 2, as.logical)
predictorMultiClass <- predict(modelFit, newdata = testDataset[, c(1:nFeatures)], type = "raw")
#Initializing the predicted labels, all are putted to false.
predictedLabels <- testDataset[, c((nFeatures+1):cols)]
predictedLabels[,] <- FALSE
#See the predicted classes
predictedClasses <- unique(predictorMultiClass)
# For each predicted classes
for(pc in predictedClasses){
indexCluster <- as.numeric(substr(pc, 2, nchar(pc)))
indexfofInstances <- which(pc == predictorMultiClass)
#The prediction is the same as the cluster. Like a LPS does.
if(summaryPatterns[indexCluster, "Radius"] == 0){
predictedLabels[indexfofInstances, pr$a[[indexCluster]]$y] <- TRUE
} else{
subdatasetBinary <- testDataset[indexfofInstances, c(1:nFeatures)]
# For each label
for(cl in 1:nlabels[nameDataset]){
if(length(binaryClassifiers[indexCluster, cl][[1]]) == 0){
predictedLabels[indexfofInstances, cl] <- labelSpace[pr$a[[indexCluster]]$x[1], cl]
} else {
modelBinaryTemp <- binaryClassifiers[indexCluster, cl][[1]]
predTemp <- predict(modelBinaryTemp, newdata = subdatasetBinary, type = "raw")
predTemp <- as.logical(substr(predTemp, 1, nchar(as.character(predTemp))-1))
predictedLabels[indexfofInstances, cl] <- predTemp
}
}
}
}
# To check
apply(predictedLabels, 2, function(x) any(is.na(x)))
hamming <- hammingLoss(predLabels = predictedLabels, trueLabels = testDataset[, c((nFeatures+1):cols)])
cat(hamming, "\n")
hammingMean <- c(hammingMean, hamming)
remove(binaryClassifiers)
remove(dataset)
remove(multiclassDataset)
remove(testDataset)
remove(pr)
remove(summaryPatterns)
}
cat("avg. Hamming Loss:", mean(hammingMean))
# Para usar edgeR es preferible utilizar los conteos puros, sin embargo podemos pasarle conteos RSEM,
# pero sin normalizar, aunque siempre serÃ¡n mejor los puros.
rm(list = ls())
pacman::p_load("edgeR", "SummarizedExperiment")
fileName <- "datasets/BLCA-genes.txt_genunnormalized"
data <- read.csv(paste0(fileName, ".csv"), sep = ",", row.names = 1)
head(data)
a <- colnames(data)
# First, all the genes with an unrecognized name (?) are removed.
data <- data[!startsWith(rownames(data), "?"), ]
extract_clase <- function(row){
if(startsWith(row[4], "01"))
return("E")
if(startsWith(row[4], "11"))
return("S")
return("")
}
aclases <-unlist(lapply(strsplit(a, split = "[.]"), extract_clase))
data <- data[, !aclases == ""]
aclases <- aclases[!aclases==""]
# Para usar edgeR es preferible utilizar los conteos puros, sin embargo podemos pasarle conteos RSEM,
# pero sin normalizar, aunque siempre serÃ¡n mejor los puros.
rm(list = ls())
pacman::p_load("edgeR", "SummarizedExperiment")
fileName <- "datasets/BLCA-genes.txt_genunnormalized"
data <- read.csv(paste0(fileName, ".csv"), sep = ",", row.names = 1)
head(data)
a <- colnames(data)
# First, all the genes with an unrecognized name (?) are removed.
data <- data[!startsWith(rownames(data), "?"), ]
extract_clase <- function(row){
if(startsWith(row[4], "01"))
return("E")
if(startsWith(row[4], "11"))
return("S")
return("")
}
aclases <-unlist(lapply(strsplit(a, split = "[.]"), extract_clase))
getwd()
library(shiny)
runApp("/media/ogreyesp/DATA/workspace/Rprojects/SAM-master/")
library(shiny)
runApp("/media/ogreyesp/DATA/workspace/Rprojects/SAM-master/")
?SAM
runApp("/media/ogreyesp/DATA/workspace/Rprojects/SAM-master/")
runApp("/media/ogreyesp/DATA/workspace/Rprojects/SAM-master/")
runApp("/media/ogreyesp/DATA/workspace/Rprojects/SAM-master/")
source('/media/ogreyesp/DATA/workspace/IMIBIC/datasets/pancreas/v2/RunSAMR.R')
source('/media/ogreyesp/DATA/workspace/IMIBIC/datasets/pancreas/v2/RunSAMR.R')
getwd()
setwd
setwd("/media/ogreyesp/DATA/workspace/IMIBIC/datasets/pancreas/v2")
library(ggpubr)
# load the csv
output <- "results/boxplots"
library(ggpubr)
# load the csv
output <- "results/boxplots"
fileName <- "Todos-NormalvsTumor.csv"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
fileName <- "Todos-NormalvsTumor"
library(ggpubr)
# load the csv
output <- "results/boxplots"
fileName <- "Todos-NormalvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "Todos-NormalvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "Todos-NormalvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset, paired = TRUE)
plot <- ggpaired(dataset, x = "Class", y = nameC,
color = "Class", line.color = "gray", line.size = 0.4,
palette = "jco") + stat_compare_means(paired = TRUE)
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "AdyacentevsLesion"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset, paired = TRUE)
plot <- ggpaired(dataset, x = "Class", y = nameC,
color = "Class", line.color = "gray", line.size = 0.4,
palette = "jco") + stat_compare_means(paired = TRUE)
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "AdyacentevsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset, paired = TRUE)
plot <- ggpaired(dataset, x = "Class", y = nameC,
color = "Class", line.color = "gray", line.size = 0.4,
palette = "jco") + stat_compare_means(paired = TRUE)
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
source('RunSAMR.R')
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "LesionvsTumor.csv"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
View(dataset)
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset, paired = TRUE)
plot <- ggpaired(dataset, x = "Class", y = nameC,
color = "Class", line.color = "gray", line.size = 0.4,
palette = "jco") + stat_compare_means(paired = TRUE)
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
library(ggpubr)
# load the csv
output <- "results/boxplots/"
fileName <- "LesionvsTumor"
paired <- FALSE
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset, paired = paired)
plot <- ggpaired(dataset, x = "Class", y = nameC,
color = "Class", line.color = "gray", line.size = 0.4,
palette = "jco") + stat_compare_means(paired = paired)
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
library(ggpubr)
#https://www.r-bloggers.com/add-p-values-and-significance-levels-to-ggplots/
# load the csv
output <- "results/statistical-tests/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "")
View(dataset)
library(ggpubr)
#https://www.r-bloggers.com/add-p-values-and-significance-levels-to-ggplots/
# load the csv
output <- "results/statistical-tests/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
View(dataset)
library(ggpubr)
#https://www.r-bloggers.com/add-p-values-and-significance-levels-to-ggplots/
# load the csv
output <- "results/statistical-tests/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset)
p <- ggboxplot(dataset, x = "Class", y = nameC,
color = "Class", palette = "jco")
#  Add p-value
p + stat_compare_means()
# To change to t-test
#p + stat_compare_means(method = "t.test")
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
library(ggpubr)
#https://www.r-bloggers.com/add-p-values-and-significance-levels-to-ggplots/
# load the csv
output <- "results/statistical-tests/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset)
p <- ggboxplot(dataset, x = "Class", y = nameC,
color = "Class", palette = "jco")
#  Add p-value
p + stat_compare_means()
# To change to t-test
#p + stat_compare_means(method = "t.test")
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
library(ggpubr)
#https://www.r-bloggers.com/add-p-values-and-significance-levels-to-ggplots/
# load the csv
output <- "results/boxplots/"
fileName <- "LesionvsTumor"
outputT <-paste0(output, fileName, "/")
if(!dir.exists(outputT)){
dir.create(outputT, recursive = T)
}
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
colnamesT <- colnames(dataset)[-ncol(dataset)]
classes <- levels(dataset[, ncol(dataset)])
colClassName <- colnames(dataset)[ncol(dataset)]
#for each column
for(nameC in colnamesT){
formula <- as.formula(paste0(nameC," ~ Class"))
a<-compare_means(formula, data = dataset)
p <- ggboxplot(dataset, x = "Class", y = nameC,
color = "Class", palette = "jco")
#  Add p-value
p + stat_compare_means()
# To change to t-test
#p + stat_compare_means(method = "t.test")
ggsave(width = 5, height = 5, filename = paste(outputT,nameC,".png",sep = ""), bg = "transparent")
}
