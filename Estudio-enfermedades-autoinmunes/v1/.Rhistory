strFilter <- paste(strFilter, " (modelFit$results[,\"",nameParameter,"\"] == modelFit$bestTune[,\"",nameParameter,"\"]) &", sep = "")
}
strFilter <- substr(strFilter, 1, nchar(strFilter)-1)
indexes <- eval(parse(text=strFilter))
results <- modelFit$results[indexes,]
results
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="adaboost",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
cNameTuning <-colnames(modelFit$bestTune)
# Maybe, there is a better way to do this filter of results
strFilter <- ""
for(nameParameter in cNameTuning){
strFilter <- paste(strFilter, " (modelFit$results[,\"",nameParameter,"\"] == modelFit$bestTune[,\"",nameParameter,"\"]) &", sep = "")
}
strFilter <- substr(strFilter, 1, nchar(strFilter)-1)
indexes <- eval(parse(text=strFilter))
results <- modelFit$results[indexes,]
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="adaboost",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
cNameTuning <-colnames(modelFit$bestTune)
# Maybe, there is a better way to do this filter of results
strFilter <- ""
for(nameParameter in cNameTuning){
strFilter <- paste(strFilter, " (modelFit$results[,\"",nameParameter,"\"] == modelFit$bestTune[,\"",nameParameter,"\"]) &", sep = "")
}
strFilter <- substr(strFilter, 1, nchar(strFilter)-1)
indexes <- eval(parse(text=strFilter))
results <- modelFit$results[indexes,]
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="adaboost",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="adaboost",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
modelFit
modelFit <- train(Species ~ ., data = iris,
method="adaboost",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="AdaBag",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="xgbTree",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="xgbTree",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="sparseLDA",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
modelFit
modelFit
# Maybe, there is a better way to do this filter of results
strFilter <- ""
for(nameParameter in cNameTuning){
strFilter <- paste(strFilter, " (modelFit$results[,\"",nameParameter,"\"] == modelFit$bestTune[,\"",nameParameter,"\"]) &", sep = "")
}
strFilter <- substr(strFilter, 1, nchar(strFilter)-1)
indexes <- eval(parse(text=strFilter))
results <- modelFit$results[indexes,]
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
cNameTuning <-colnames(modelFit$bestTune)
# Maybe, there is a better way to do this filter of results
strFilter <- ""
for(nameParameter in cNameTuning){
strFilter <- paste(strFilter, " (modelFit$results[,\"",nameParameter,"\"] == modelFit$bestTune[,\"",nameParameter,"\"]) &", sep = "")
}
strFilter <- substr(strFilter, 1, nchar(strFilter)-1)
indexes <- eval(parse(text=strFilter))
results <- modelFit$results[indexes,]
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
results
modelFit$bestTune
rownames(modelFit$bestTune)
modelFit$results[25]
modelFit$results[25,]
results
modelFit$bestTune
rownames(modelFit$bestTune)
rownames(modelFit$bestTune)[1]
as.integer(rownames(modelFit$bestTune)[1])
modelFit$results[as.integer(rownames(modelFit$bestTune)[1]),]
results <- modelFit$results[as.integer(rownames(modelFit$bestTune)[1]),]
results
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="sdwd",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="sdwd",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
#cNameTuning <-colnames(modelFit$bestTune)
# Maybe, there is a better way to do this filter of results
#strFilter <- ""
#for(nameParameter in cNameTuning){
# strFilter <- paste(strFilter, " (modelFit$results[,\"",nameParameter,"\"] == modelFit$bestTune[,\"",nameParameter,"\"]) &", sep = "")
#}
#strFilter <- substr(strFilter, 1, nchar(strFilter)-1)
#indexes <- eval(parse(text=strFilter))
#results <- modelFit$results[indexes,]
results <- modelFit$results[as.integer(rownames(modelFit$bestTune)[1]),]
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
results
getModelInfo("sdwd")
caret::modelLookup("sdwd")
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="sdwd",
metric = "AUC",
tuneLength = 2,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="RRF",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
results
results <- modelFit$results[as.integer(rownames(modelFit$bestTune)[1]),]
plot(varImp(modelFit, scale=FALSE))
plot(modelFit)
results
?prediction
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="sdwd",
metric = "AUC",
trControl = fitControl)
modelLookup("xgbLinear")
install.packages("fastAdaboost")
install.packages("fastAdaboost")
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="adaboost",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
warnings()
_install.packages
?install.packages
install.packages(c("adabag", "plyr"))
install.packages(c("adabag", "plyr"))
install.packages(c("adabag", "plyr"))
install.packages(c("adabag", "plyr"))
install.packages(c("adabag", "plyr"))
install.packages(c("adabag", "plyr"))
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
#Required packages
packages <-c("adabag", "plyr")
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="AdaBoost.M1",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
#Required packages
packages <-c("adabag", "plyr")
path <- "D:/OneDrive - Universidad de Córdoba/workspace/Diabetes-paper/diabetic_data-fourthStep-preproc"
mydata <- read.csv(paste(path,".csv",sep = ""), sep = ",")
numClasses <- length(levels(mydata[,ncol(mydata)]))
#we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="repeatedcv", number=10, repeats = 3, classProbs=TRUE,
savePredictions = TRUE, search="grid", allowParallel= TRUE, summaryFunction = multiClassSummary)
data("iris")
set.seed(825)
modelFit <- train(Species ~ ., data = iris,
method="AdaBoost.M1",
metric = "AUC",
tuneLength = 10,
trControl = fitControl)
wants <- c("adabag", "plyr")
has   <- wants %in% rownames(installed.packages())
if(any(!has)) install.packages(wants[!has])
install.packages(wants[!has])
library(plyr)
library(plyr)
remove.packages("plyr")
source("cotraining.R")
?randperm
library(pracma)
?randperm
randperm(1:6, 3)
randperm(1:6)
randperm(1:6)
randperm(1:6,4)
aux <- zeros(10,2)
aux
randperm(100)
randperm(10)
perms(c(1,2,3))
?which
install.packages("grConvert")
install.packages("grConvert", repos="http://R-Forge.R-project.org")
install.packages("grImport", repos="http://R-Forge.R-project.org")
install.packages("grImport2", repos="http://R-Forge.R-project.org")
install.packages("devtools")
library(devtools)
install_github("sjp/grConvert")
install_github("sjp/grConvert")
library(grConverter)
library(grConvert)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/enfermedades-autoinmunes/")
mydata <- read.csv("results/ControlesVSEnfermosLinfocitos-preproc-sortedfeatures.txt", sep = "\t")
mydata
colnames(mydata)<- c("index", "name","imp")
mydata
mydata <- read.csv("results/ControlesVSEnfermosLinfocitos-preproc-sortedfeatures.txt", sep = "\t", header = F)
mydata
colnames(mydata)<- c("index", "name","imp")
mydata
library(bclust)
viplot(mydata$imp,xlab = as.vector(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 7)
viplot(mydata$imp,xlab = as.vector(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 3)
viplot(mydata$imp,xlab = as.vector(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 8)
viplot(mydata$imp,xlab = as.vector(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12)
viplot(mydata$imp,xlab = as.vector(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 1)
viplot(mydata$imp,xlab = as.vector(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 1)
mydata$name
mydata$name[1]
mydata[1,"name"]
as.vector(mydata$name)
as.character(mydata$name)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 1)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 20)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12)
png(paste("results/", fileName,"-VarImp.png",sep = ""), width = 12, height = 8, units="in", res=200)
png(paste("results/xxx-VarImp.png",sep = ""), width = 12, height = 8, units="in", res=200)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12)
dev.off()
png(paste("results/xxx-VarImp.png",sep = ""), width = 12, height = 10, units="in", res=200)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12)
dev.off()
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 12)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 7)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 1)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 14)
?viplot
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 14)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 14)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 12)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10)
png(paste("results/xxx-VarImp.png",sep = ""), width = 16, height = 10, units="in", res=200)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10)
dev.off()
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.srt = 10)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.srt = 0)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.srt = 0)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.srt = -10)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.srt = 1)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.cex = 1)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.cex = 2)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.cex = 1)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.cex = 0.5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 6, xlab.cex = 0.5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.3)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.5)
viplot(mydata$imp,xlab = substr(as.character(mydata$name),1,5), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 8, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 10, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 11, xlab.cex = 0.7)
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12, xlab.cex = 0.7)
mydata <- read.csv("results/ControlesVSEnfermosMonocitos-preproc-sortedfeatures.txt", sep = "\t", header = F)
colnames(mydata)<-c("index","name","imp")
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12, xlab.cex = 0.7)
mydata <- read.csv("results/ControlesVsEnfermosNeutrofilos-preproc-sortedfeatures.txt", sep = "\t", header = F)
colnames(mydata)<-c("index","name","imp")
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12, xlab.cex = 0.7)
mydata <- read.csv("results/PreVsPostLinfocitos-preproc-sortedfeatures.txt", sep = "\t", header = F)
colnames(mydata)<-c("index","name","imp")
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12, xlab.cex = 0.7)
mydata <- read.csv("results/PreVSPostMonocitos-preproc-sortedfeatures.txt", sep = "\t", header = F)
colnames(mydata)<-c("index","name","imp")
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12, xlab.cex = 0.7)
mydata <- read.csv("results/PreVSPostNeutrofilos-preproc-sortedfeatures.txt", sep = "\t", header = F)
colnames(mydata)<-c("index","name","imp")
viplot(mydata$imp,xlab = as.character(mydata$name), col=heat.colors(length(mydata$imp)), xlab.mar = 12, xlab.cex = 0.7)
