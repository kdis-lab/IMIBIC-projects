fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
g <- ggplot(modelFit$pred, aes(m = N, d=factor(obs, levels = c("S", "N")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", modelFit$results[1,"ROC"]))
ggsave(width = 8, height = 5, filename = paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""), bg = "transparent")
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
?createDataPartition
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
Train <- createDataPartition(dataset$DIABETES, p=0.66, list=FALSE, times=5)
training <- dataset[Train, ]
testing <- dataset[-Train, ]
set.seed(123)
#fitControl <- trainControl(method="repeatedcv", number = 10,
#                           repeats = 3, classProbs = TRUE,
#                           savePredictions = TRUE, allowParallel= TRUE,
#                           summaryFunction = twoClassSummary, verboseIter = FALSE, search="grid")
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = training,
method="glm",
metric = "ROC",
maximize = TRUE,
family="binomial")
?trainControl
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
Train <- createDataPartition(dataset$DIABETES, p=0.66, list=FALSE, times=5)
training <- dataset[Train, ]
testing <- dataset[-Train, ]
set.seed(123)
fitControl <- trainControl(method="LGOCV", number = 5,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE, search="grid")
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = training,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl,
family="binomial")
auc <- modelFit$results[1, "ROC"]
auc
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
Train <- createDataPartition(dataset$DIABETES, p=0.66, list=FALSE, times=5)
training <- dataset[Train, ]
testing <- dataset[-Train, ]
set.seed(123)
fitControl <- trainControl(method="LGOCV", number = 5,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE, search="grid")
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = dataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl,
family="binomial")
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
Train <- createDataPartition(dataset$DIABETES, p=0.66, list=FALSE, times=5)
training <- dataset[Train, ]
testing <- dataset[-Train, ]
set.seed(123)
fitControl <- trainControl(method="LGOCV", number = 5,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE, search="grid")
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = dataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl,
family="binomial")
modelFit$results
predict(modelFit, newdata=testing, type="prob")
predict(modelFit, newdata=testing)
predict(modelFit, newdata=testing, type="prob")
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
Train <- createDataPartition(dataset$DIABETES, p=0.66, list=FALSE, times=5)
training <- dataset[Train, ]
testing <- dataset[-Train, ]
Train <- createDataPartition(dataset$DIABETES, p=0.66, list=FALSE)
training <- dataset[Train, ]
testing <- dataset[-Train, ]
modelFit <- train(form, data = training,
method="glm",
metric = "ROC",
maximize = TRUE,
family="binomial")
fitControl <- trainControl(method="LGOCV", number = 5,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE, search="grid")
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = training,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl,
family="binomial")
predict(modelFit, newdata=testing, type="prob")
predict(modelFit, newdata=testing)
?twoClassSummary
View(testing)
predict <- predict(modelFit, newdata=testing)
predict
confusionMatrix(data = predict, reference = testing$DIABETES)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
set.seed(123)
fitControl <- trainControl(method="LGOCV", number = 5,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = dataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl,
family="binomial")
modelFit
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
plotROC <- TRUE
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
set.seed(123)
fitControl <- trainControl(method="LGOCV", number = 5,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
modelFit <- train(form, data = dataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl,
family="binomial")
predict <- predict(modelFit, newdata=dataset)
confusionMatrix(data = predict, reference = dataset$DIABETES)
predict <- predict(modelFit, newdata=dataset)
confusionMatrix(data = predict, reference = dataset$DIABETES)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
#library(doMC)
#registerDoMC(cores = 5)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
threshold <- 0.65
plotROC <- TRUE
output <- "results/Classification/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
rankingFeature <- read.csv("Diabetes-preproc-sortedfeatures.csv", sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="LogitBoost",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
g <- ggplot(modelFit$pred, aes(m = N, d=factor(obs, levels = c("S", "N")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", modelFit$results[1,"ROC"]))
ggsave(width = 8, height = 5, filename = paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""), bg = "transparent")
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
#library(doMC)
#registerDoMC(cores = 5)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
threshold <- 0.65
plotROC <- TRUE
output <- "results/Classification/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc.csv")
rankingFeature <- read.csv("Diabetes-preproc-sortedfeatures.csv", sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="LogitBoost",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
g <- ggplot(modelFit$pred, aes(m = N, d=factor(obs, levels = c("S", "N")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", modelFit$results[1,"ROC"]))
ggsave(width = 8, height = 5, filename = paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""), bg = "transparent")
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
library(caret)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
fileT <- "Diabetes-raw"
dataset <- read.csv(paste(fileT,".csv",sep = ""), na.strings = "")
threshold <- 0.7
cnames <- colnames(dataset)[1:15]
for(index in cnames){
sumaNA<-sum(is.na(dataset[,index]))
indexesCeros <- dataset[,index]==0 & !is.na(dataset[,index])
sumacero <- sum(indexesCeros)
to <- sumaNA+sumacero
#Remove the factor if the number of NA and ceros is greater than the threshold
if(to/nrow(dataset) >= threshold){
print("Removing...")
print(paste(index,": NA (", sumaNA, ") ", "Ceros (", sumacero , ") percent:", to/nrow(dataset)))
dataset[,index] <-  NULL
}
else{
#removing Os
dataset[indexesCeros, index] <- NA
}
}
methods <- c("bagImpute")
preProcValues <- preProcess(dataset, method = methods)
datasetTransformed <- predict(preProcValues, dataset)
#detecting inconsistent or dupplicated examples
datasetTransformed <- datasetTransformed[!duplicated(datasetTransformed[,1:(ncol(datasetTransformed)-1)]),]
write.table(datasetTransformed, file= paste(fileT, "-preproc2.csv",sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = TRUE, na = "")
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
library(caret)
library(ggplot2)
library(plotROC)
library(pROC)
library(ROCR)
#library(doMC)
#registerDoMC(cores = 5)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/diabetes/v3/")
threshold <- 0.65
plotROC <- TRUE
output <- "results/Classification/"
#load the dataset and ranking of features
dataset <-  read.csv("Diabetes-preproc2.csv")
rankingFeature <- read.csv("Diabetes-preproc-sortedfeatures.csv", sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
g <- ggplot(modelFit$pred, aes(m = N, d=factor(obs, levels = c("S", "N")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", modelFit$results[1,"ROC"]))
ggsave(width = 8, height = 5, filename = paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""), bg = "transparent")
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
