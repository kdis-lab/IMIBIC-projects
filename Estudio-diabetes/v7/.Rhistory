method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(subdataset$DIABETES, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
debugSource('D:/workspace/IMIBIC/datasets/diabetes/v7/SearchBasedRankingFeatures-LogisticRegression.R')
library(caret)
library(pROC)
# It only works on linux
#library(doMC)
#registerDoMC(cores = 2)
threshold <- 0.75
plotROC <- TRUE
fileName <- "0h-preproc"
output <- paste("results/preprocessing/", fileName, "/", sep = "")
#load the dataset and ranking of features
dataset <- read.csv(paste(fileName, ".csv", sep = ""))
rankingFeature <- read.csv(paste("results/", fileName, "-sortedfeatures.csv", sep = ""), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(subdataset$DIABETES, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
library(caret)
library(pROC)
# It only works on linux
#library(doMC)
#registerDoMC(cores = 2)
threshold <- 0.75
plotROC <- TRUE
fileName <- "4h-preproc"
output <- paste("results/preprocessing/", fileName, "/", sep = "")
#load the dataset and ranking of features
dataset <- read.csv(paste(fileName, ".csv", sep = ""))
rankingFeature <- read.csv(paste("results/", fileName, "-sortedfeatures.csv", sep = ""), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(subdataset$DIABETES, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
library(caret)
library(pROC)
# It only works on linux
#library(doMC)
#registerDoMC(cores = 2)
threshold <- 0.75
plotROC <- TRUE
fileName <- "0h"
output <- paste("results/without-preprocessing/", fileName, "/", sep = "")
#load the dataset and ranking of features
dataset <- read.csv(paste(fileName, ".csv", sep = ""))
rankingFeature <- read.csv(paste("results/", fileName, "-sortedfeatures.csv", sep = ""), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(subdataset$DIABETES, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
library(caret)
library(pROC)
# It only works on linux
#library(doMC)
#registerDoMC(cores = 2)
threshold <- 0.75
plotROC <- TRUE
fileName <- "4h"
output <- paste("results/without-preprocessing/", fileName, "/", sep = "")
#load the dataset and ranking of features
dataset <- read.csv(paste(fileName, ".csv", sep = ""))
rankingFeature <- read.csv(paste("results/", fileName, "-sortedfeatures.csv", sep = ""), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(subdataset$DIABETES, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
debugSource('D:/workspace/IMIBIC/datasets/diabetes/v7/SearchBasedRankingFeatures-LogisticRegression.R')
View(subdataset)
modelFit$results
library(caret)
fileT <- "0h-4h.csv"
dataset <- read.csv(fileT, na.strings = "", sep = ",", row.names = 1)
methods <- c("zv", "nzv", "center","scale","YeoJohnson")
preProcValues <- preProcess(dataset, method = methods)
datasetTransformed <- predict(preProcValues, dataset)
datasetTransformed <- datasetTransformed[!duplicated(datasetTransformed[,1:(ncol(datasetTransformed)-1)]),]
write.table(datasetTransformed, file= paste(fileT, "-preproc.csv",sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
model<- load("D:\workspace/IMIBIC/datasets/diabetes/v7/results/without-preprocessing/0h-4h/modelfit-LogisticRegression-1.rds")
model<- load("D://workspace/IMIBIC/datasets/diabetes/v7/results/without-preprocessing/0h-4h/modelfit-LogisticRegression-1.rds")
model<- readRDS("D://workspace/IMIBIC/datasets/diabetes/v7/results/without-preprocessing/0h-4h/modelfit-LogisticRegression-1.rds")
model$results
library(caret)
predictors(model)
vars <- predictors(modelFit)
library(caret)
library(pROC)
# It only works on linux
#library(doMC)
#registerDoMC(cores = 2)
threshold <- 0.75
plotROC <- TRUE
fileName <- "0h-4h"
output <- paste("results/without-preprocessing/", fileName, "/", sep = "")
#load the dataset and ranking of features
dataset <- read.csv(paste(fileName, ".csv", sep = ""))
rankingFeature <- read.csv(paste("results/", fileName, "-sortedfeatures.csv", sep = ""), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(subdataset$DIABETES, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
subdataset$DIABETES
length(subdataset$DIABETES)
length(modelFit$pred$S)
modelFit$results
modelFit$pred
modelFit$pred$obs
modelFit$pred
library(caret)
library(pROC)
# It only works on linux
#library(doMC)
#registerDoMC(cores = 2)
threshold <- 0.75
plotROC <- TRUE
fileName <- "0h-4h"
output <- paste("results/without-preprocessing/", fileName, "/", sep = "")
#load the dataset and ranking of features
dataset <- read.csv(paste(fileName, ".csv", sep = ""))
rankingFeature <- read.csv(paste("results/", fileName, "-sortedfeatures.csv", sep = ""), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,"LogisticRegression.csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
modelFit <- train(form, data = subdataset,
method="glm",
metric = "ROC",
maximize = TRUE,
trControl = fitControl, family="binomial")
auc <- modelFit$results[1, "ROC"]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-LogisticRegression","-", nrow(df),".rds", sep = ""))
#######################To generate the ROC curve of the best model.
if(plotROC){
result.roc <- roc(modelFit$pred$obs, modelFit$pred$S) # Draw ROC curve.
plot(result.roc, print.auc = TRUE)
dev.copy(png, paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""))
dev.off()
ggsave(width = 8, height = 5, filename = paste(output,"modelfit-LogisticRegression","-", nrow(df),".png",sep = ""), bg = "transparent")
}
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
