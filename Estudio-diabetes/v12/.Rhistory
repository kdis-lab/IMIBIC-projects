x
pr
x <- matrix(sample(c(FALSE, TRUE), 200, rep=TRUE), ncol=10)
pr <- proximus(x, max.radius=8)
pr
summary(pr)
### example from paper
x <- rlbmat()
pr <- proximus(x, max.radius=8, debug=TRUE)
summary(pr)
pr$a
x[c(61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80), ]
pr$a
x[c(61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80), c(37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52)]
pr$a
dataset<-read.csv(file = "/home/ogreyesp/Desktop/emotions.csv", sep = ",", header = F)
View(dataset)
dataset<-dataset[,c(73:78)]
as.logical(dataset)
matrix(dataset)
matrix(dataset)
?matrix
?proximus
?matrix
m<-matrix(nrow = 593, ncol = 6)
dataset
data.matrix(dataset)
proximus(data.matrix(dataset), max.radius = 8)
m<-data.matrix(dataset)
class(m)
apply(m, 2, as.logical)
m<-apply(m, 2, as.logical)
pr<-proximus(m, max.radius = 8)
pr
summary(pr)
pr<-proximus(m, max.radius = 5)
summary(pr)
pr<-proximus(m, max.radius = 20)
summary(pr)
pr<-proximus(m, max.radius = 8)
pr$a
m[c(1,4,6,10),3]
m[c(5,15,60,71,91), c(4,5)]
m[c(5,15,60,71,91,125,153,158,187,200,208,216,219,253,256,295,300,301,303), c(4,5)]
m[c(2,3,7,8,9,13,16,19,21,24,25,28,31,33,34,35,39,40,42),c(1,6)]
cor(m, method = c("pearson"))
x = c(1,  1,  0,  0,  1,  0,  1,  1,  1)
y = c(1,  1,  0,  0,  0,  0,  1,  1,  1)
cor(x,y)
sqrt(chisq.test(table(m[,1],m[2]), correct=FALSE)$statistic/length(593))
sqrt(chisq.test(table(m[,1],m[,2]), correct=FALSE)$statistic/length(593))
sqrt(chisq.test(table(m[,4],m[,5]), correct=FALSE)$statistic/length(593))
sqrt(chisq.test(table(m[,1],m[,6]), correct=FALSE)$statistic/length(593))
install.packages("GenomicRanges")
source("https://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite("GenomicRanges")
library(GenomicRanges)
phicoef(m[,1], m[,6])
phicoef(m[,4], m[,5])
strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47")
strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", sep="\t")
?strsplit
strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t")
unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))
sum(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t")))
sum(as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))))
73.21/1758
73.21/1758
sum(as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))))
sum(as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t"))))
c<-as.numeric(unlist(strsplit("73.21	196.01	112.86	162.06	230.58	8.84	0.00	62.35	0.00	0.00	0.00	8.09	0.00	152.11	0.00	0.00	0.00	0.00	148.10	0.00	186.63	0.00	0.00	12.92	0.00	0.00	0.00	0.00	0.00	0.00	80.13	0.00	23.17	0.00	0.00	0.00	0.00	0.00	0.00	122.11	0.00	11.09	0.00	0.00	0.00	0.00	90.32	0.00	0.00	0.00	0.00	77.47", split="\t")))
sum(c)/length(c)
73.21/33.80865
remove(list = ls())
library(cba)
library(caret)
library(pROC)
library(doMC)
registerDoMC(cores = 2)
source("EvaluationMeasure.R")
nlabels <- c("emotions"=6)
nameDataset <- "emotions"
hammingMean <- c()
#For each random fold
for(fold in 1:5){
cat("Fold:",fold,"\n")
dataset <- read.csv(file = paste0("datasets/", nameDataset, "-train", fold,".csv"), sep = ",", header = F)
cols <- ncol(dataset)
nFeatures <- cols - nlabels[nameDataset]
#Converting the label columns in logical factors
dataset[, c((nFeatures+1):cols)] <- apply(dataset[, c((nFeatures+1):cols)], 2, as.logical)
#Executing the Proximus algorithms
labelSpace <- data.matrix(dataset[, c((nFeatures+1):cols)])
labelSpace <- apply(labelSpace, 2, as.logical)
# Compute the cardinality of the training set
cardinality <- mean(apply(labelSpace, 1, sum))
pr <- proximus(labelSpace, max.radius= ceiling(cardinality))
summary(pr)
summaryPatterns <- summary(pr)$pattern
numberCluster <- length(pr$a)
#Creating the new dataset for multi-class prediction
multiclassDataset <- dataset[ , c(1:nFeatures)]
multiclassDataset <- cbind(multiclassDataset, Class= rep("C1", nrow(multiclassDataset)))
levels(multiclassDataset$Class) <- paste0("C", c(1:numberCluster))
numberInstances <- nrow(multiclassDataset)
caseWeights <- rep(1, numberInstances)
for(c in 1:numberCluster){
#Creating class c
cat("Index:", c, " Labels:", pr$a[[c]]$y, " ", "instances:" , length(pr$a[[c]]$x), "\n")
multiclassDataset[pr$a[[c]]$x, "Class"] <- as.factor(paste0("C", c))
# Computing the case weights for handling imbalanced problems
caseWeights[pr$a[[c]]$x] <- numberInstances/(numberCluster* length(pr$a[[c]]$x))
}
# Using the new dataset as training set
fitControl <- trainControl(method="repeatedcv", number = 10, repeats = 1, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = multiClassSummary, verboseIter = FALSE)
modelFit <- train(Class ~ ., data = multiclassDataset,
method="C5.0",  # implementation of random forest that supports case weights
metric = "AUC",
maximize = TRUE,
trControl = fitControl, tuneLength = 5, weights = caseWeights, preProcess = c("nzv","zv","center", "scale"))
# Proccess for the creation of binary classifiers
binaryClassifiers <- matrix(list(list()),  numberCluster, nlabels[nameDataset])
BinaryFitControl <- trainControl(method="repeatedcv", number = 10, repeats = 1, classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE,
summaryFunction = twoClassSummary, verboseIter = FALSE)
for(indexCluster in 1:numberCluster){
if(summaryPatterns[indexCluster, "Radius"] > 0){
# subdataset with all labels in the cluster
subdataset <- dataset[pr$a[[indexCluster]]$x,]
# For each label
for(indexLabel in (nFeatures+1):(nFeatures+nlabels[nameDataset])){
values <- unique(subdataset[, indexLabel])
if(length(values) == 2){
# If there are two values, then train a classifier and predict with this classifier
binarySubdataset <- subdataset[, c(1:nFeatures, indexLabel)]
# Computing the case weights for handling imbalanced problems
numberBinaryInstances <- nrow(binarySubdataset)
trueInstances <- sum(binarySubdataset[, nFeatures+1])
negativeInstances <- numberBinaryInstances - trueInstances
binaryCaseWeights <- rep(1, numberBinaryInstances)
binaryCaseWeights[binarySubdataset[, nFeatures+1]==TRUE] <- numberBinaryInstances/(2 * trueInstances)
binaryCaseWeights[binarySubdataset[, nFeatures+1]==FALSE] <- numberBinaryInstances/(2 * negativeInstances)
#Converting the last column to factor. Los valores True y False no se pueden dejar porque dan error.
binarySubdataset[, nFeatures+1] <- as.factor(binarySubdataset[, nFeatures+1])
levels(binarySubdataset[, nFeatures+1]) <- make.names(levels(factor(binarySubdataset[, nFeatures+1])))
binaryClassifiers[indexCluster, indexLabel-nFeatures][[1]] <- train(as.formula(paste0(colnames(binarySubdataset)[nFeatures+1], "~ .")), data = binarySubdataset,
method="rf",  # implementation of random forest that supports case weights
metric = "ROC",
maximize = TRUE,
trControl = BinaryFitControl,
tuneLength = 5, weights = binaryCaseWeights, preProcess = c("nzv","zv","center", "scale"))
}
}
}
}
testDataset <-read.csv(file = paste0("datasets/", nameDataset, "-test", fold,".csv"), sep = ",", header = F)
testDataset[, c((nFeatures+1):cols)] <- apply(testDataset[, c((nFeatures+1):cols)], 2, as.logical)
predictorMultiClass <- predict(modelFit, newdata = testDataset[, c(1:nFeatures)], type = "raw")
#Initializing the predicted labels, all are putted to false.
predictedLabels <- testDataset[, c((nFeatures+1):cols)]
predictedLabels[,] <- FALSE
#See the predicted classes
predictedClasses <- unique(predictorMultiClass)
# For each predicted classes
for(pc in predictedClasses){
indexCluster <- as.numeric(substr(pc, 2, nchar(pc)))
indexfofInstances <- which(pc == predictorMultiClass)
#The prediction is the same as the cluster. Like a LPS does.
if(summaryPatterns[indexCluster, "Radius"] == 0){
predictedLabels[indexfofInstances, pr$a[[indexCluster]]$y] <- TRUE
} else{
subdatasetBinary <- testDataset[indexfofInstances, c(1:nFeatures)]
# For each label
for(cl in 1:nlabels[nameDataset]){
if(length(binaryClassifiers[indexCluster, cl][[1]]) == 0){
predictedLabels[indexfofInstances, cl] <- labelSpace[pr$a[[indexCluster]]$x[1], cl]
} else {
modelBinaryTemp <- binaryClassifiers[indexCluster, cl][[1]]
predTemp <- predict(modelBinaryTemp, newdata = subdatasetBinary, type = "raw")
predTemp <- as.logical(substr(predTemp, 1, nchar(as.character(predTemp))-1))
predictedLabels[indexfofInstances, cl] <- predTemp
}
}
}
}
# To check
apply(predictedLabels, 2, function(x) any(is.na(x)))
hamming <- hammingLoss(predLabels = predictedLabels, trueLabels = testDataset[, c((nFeatures+1):cols)])
cat(hamming, "\n")
hammingMean <- c(hammingMean, hamming)
remove(binaryClassifiers)
remove(dataset)
remove(multiclassDataset)
remove(testDataset)
remove(pr)
remove(summaryPatterns)
}
cat("avg. Hamming Loss:", mean(hammingMean))
# Para usar edgeR es preferible utilizar los conteos puros, sin embargo podemos pasarle conteos RSEM,
# pero sin normalizar, aunque siempre serán mejor los puros.
rm(list = ls())
pacman::p_load("edgeR", "SummarizedExperiment")
fileName <- "datasets/BLCA-genes.txt_genunnormalized"
data <- read.csv(paste0(fileName, ".csv"), sep = ",", row.names = 1)
head(data)
a <- colnames(data)
# First, all the genes with an unrecognized name (?) are removed.
data <- data[!startsWith(rownames(data), "?"), ]
extract_clase <- function(row){
if(startsWith(row[4], "01"))
return("E")
if(startsWith(row[4], "11"))
return("S")
return("")
}
aclases <-unlist(lapply(strsplit(a, split = "[.]"), extract_clase))
data <- data[, !aclases == ""]
aclases <- aclases[!aclases==""]
# Para usar edgeR es preferible utilizar los conteos puros, sin embargo podemos pasarle conteos RSEM,
# pero sin normalizar, aunque siempre serán mejor los puros.
rm(list = ls())
pacman::p_load("edgeR", "SummarizedExperiment")
fileName <- "datasets/BLCA-genes.txt_genunnormalized"
data <- read.csv(paste0(fileName, ".csv"), sep = ",", row.names = 1)
head(data)
a <- colnames(data)
# First, all the genes with an unrecognized name (?) are removed.
data <- data[!startsWith(rownames(data), "?"), ]
extract_clase <- function(row){
if(startsWith(row[4], "01"))
return("E")
if(startsWith(row[4], "11"))
return("S")
return("")
}
aclases <-unlist(lapply(strsplit(a, split = "[.]"), extract_clase))
getwd()
setwd("/media/ogreyesp/DATA/workspace/IMIBIC/datasets/diabetes/v12")
fileName <- paste0("Alldiabetes")
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "U50h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
dataset$Sexo
sexo
t.test(as.formula("BMI ~ Class"), data= dataset)
?t.test
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
mean(dataset$BMI)
?mean
aggregate(BMI ~ Class, dataset$BMI, mean)
aggregate(BMI ~ Class, dataset, mean)
aggregate(Edad ~ Class, dataset, mean)
table(dataset$Class)
dataset[dataset$Class=="S"]
dataset[dataset$Class=="S",]
dataset[dataset$Class=="S", "BMI"]
mean(dataset[dataset$Class=="S", "BMI"])
aggregate(BMI ~ Class, dataset, mean)
aggregate(BMI ~ Class, dataset, mean)["BMI"]
aggregate(BMI ~ Class, dataset, mean)[2,"BMI"]
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2,"BMI"]
dataset[dataset$Class=="S", "BMI"] - meanBMIClassS
dataset[dataset$Class=="S", "BMI"] - meanBMIClassS
power(dataset[dataset$Class=="S", "BMI"] - meanBMIClassS, 2)
?power
(dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
(dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)
(dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)
(dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
which(distance==max(distance))
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
which(distance==max(distance))
dataset[-row,]
row <- which(distance==max(distance))
dataset[-row,]
aggregate(BMI ~ Class, dataset[-row,], mean)
aggregate(BMI ~ Class, dataset, mean)
aggregate(BMI ~ Class, dataset[-row,], mean)
aggregate(BMI ~ Class, dataset[-row,], mean)
aggregate(BMI ~ Class, dataset, mean)
dataset[dataset$Class=="S", "BMI"]
dataset[dataset$Class=="S", "BMI"][87]
nrow(dataset[dataset$Class=="S",])
nrow(dataset[dataset$Class=="N",])
View(dataset)
nrowN <- nrow(dataset[dataset$Class=="N",])
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
nrowN <- nrow(dataset[dataset$Class=="N",])
row+nrowN
dataset[193,]
dataset[193,"BMI"]
dataset[193,c("BMI","Class")]
dataset[-(row+nrowN),]
tempData <- dataset[-(row+nrowN),]
aggregate(BMI ~ Class, tempData, mean)
t.test(as.formula("BMI ~ Class"), data= tempData, alternative="less")
t.test(as.formula("Sexo ~ Class"), data= tempData, alternative="less")
sexo <- as.factor(tempData$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, tempData$Class)
tab
chisq.test(tab)
?t.test
getOption("na.action")
fileName <- paste0("Alldiabetes")
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "U50h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2,"BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
dataset <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, dataset$Class)
tab
chisq.test(tab)
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="less"))
}
fileName <- paste0("Alldiabetes")
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "U50h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2,"BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
dataset <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, dataset$Class)
tab
chisq.test(tab)
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="less")
fileName <- paste0("Alldiabetes")
scenario <-"0h"
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "U50h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2,"BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
dataset <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, dataset$Class)
tab
chisq.test(tab)
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="less"))
}
fileName <- paste0("Alldiabetes")
scenario <-"0h"
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "U50h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2,"BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
dataset <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, dataset$Class)
tab
chisq.test(tab)
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="greater"))
}
fileName <- paste0("Alldiabetes")
scenario <-"0h"
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "U50h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="greater"))
}
scenario <-"4h"
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="greater"))
}
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset, alternative="greater")
t.test(as.formula("Edad ~ Class"), data= dataset)
fileName <- paste0("Alldiabetes")
scenario <-"0h"
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2, "BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
dataset <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset)
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, dataset$Class)
tab
chisq.test(tab)
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="greater"))
}
fileName <- paste0("Alldiabetes")
scenario <-"4h"
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2, "BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
dataset <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= dataset, alternative="less")
t.test(as.formula("Edad ~ Class"), data= dataset)
sexo <- as.factor(dataset$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, dataset$Class)
tab
chisq.test(tab)
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="greater"))
}
fileName <- paste0("Alldiabetes")
scenario <-"4h"
genesScenarios=list("0h"=c("U20h","U40h", "U6ATAC0h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2, "BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
datasetTemp <- dataset[-(row+nrowN),]
t.test(as.formula("BMI ~ Class"), data= datasetTemp, alternative="less")
t.test(as.formula("Edad ~ Class"), data= datasetTemp)
sexo <- as.factor(datasetTemp$Sexo)
levels(sexo) <- c("H", "M")
tab <-table(sexo, datasetTemp$Class)
tab
chisq.test(tab)
for(gen in genesScenarios[[scenario]]){
print(t.test(as.formula(paste0(gen, " ~ Class")), data= dataset, alternative="greater"))
}
fileName <- paste0("Alldiabetes")
scenario <-"4h"
genesScenarios=list("0h"= c("U20h", "U40h", "U6ATAC0h", "ESRP10h", "SRSF10h"),
"4h"=c("U44h", "U24h", "U64h", "U6ATAC4h", "U4ATAC4h", "U124h", "NOVA14h", "ESRP14h", "SRSF14h"))
#load the dataset
dataset <-read.csv(paste0(fileName, ".csv"), sep = ",", na.strings = "", row.names = 1)
meanBMIClassS <- aggregate(BMI ~ Class, dataset, mean)[2, "BMI"]
# To detect the element more distant from the mean
distance <- (dataset[dataset$Class=="S", "BMI"] - meanBMIClassS)^2
#Indice relativo respecto a la clase S
row <- which(distance==max(distance))
# The number of samples in class N
nrowN <- nrow(dataset[dataset$Class=="N",])
row+nrowN
dataset[193,]
