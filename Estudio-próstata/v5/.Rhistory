write.table(varImportance$importance, file= paste(outputFolder,"varImportance-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
# To save the model to disk
saveRDS(modelFit, paste(outputFolder,"modelfit-",algorithm, ".rds", sep = ""))
# To save which predictors were used in the final model.
write.table(data.frame(Predictor = predictors(modelFit)), file= paste(outputFolder,"predictors-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = FALSE, na = "")
#Only plot the graph for those model that contain tunning process
if(nrow(modelFit$results)>1){
ggplot(modelFit)
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-",metricOpt,"-tuning",".png",sep = ""), bg = "transparent")
}
#######################To generate the ROC curve of the best model.
bestIndex <- rownames(modelFit$bestTune)[1]
selectedIndices <- modelFit$pred$mtry == modelFit$bestTune[1, "mtry"]
results <- modelFit$results[bestIndex,"ROC"]
g <- ggplot(modelFit$pred[selectedIndices,], aes(m = M, d=factor(obs, levels = c("BT","M")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", results))
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-","ROC-Curve",".png",sep = ""), bg = "transparent")
modelFit$finalModel
library(caret)
library(plotROC)
setwd("/media/oscar/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
outputFolder <- "results/"
#Not available in Windows
# library(doMC)
# registerDoMC(cores = 5)
## All subsequent models are then run in parallel
mydata <- read.csv("Grasso-ControlesvsM.csv")
algorithm <- "rf"
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
set.seed(123)
# we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="LOOCV", classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE, search = "grid",
summaryFunction = summaryFunction, verboseIter = FALSE)
form <- as.formula(paste(colnames(mydata)[ncol(mydata)]," ~ ."))
#execute the algorithms
modelFit <- train(form, data = mydata,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 10,
trControl = fitControl)
#Saving all the results
write.table(modelFit$results, file= paste(outputFolder,"results-", algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = TRUE, na = "")
#Saving the variable importance
varImportance <- varImp(modelFit, scale= TRUE)
write.table(varImportance$importance, file= paste(outputFolder,"varImportance-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
# To save the model to disk
saveRDS(modelFit, paste(outputFolder,"modelfit-",algorithm, ".rds", sep = ""))
# To save which predictors were used in the final model.
write.table(data.frame(Predictor = predictors(modelFit)), file= paste(outputFolder,"predictors-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = FALSE, na = "")
#Only plot the graph for those model that contain tunning process
if(nrow(modelFit$results)>1){
ggplot(modelFit)
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-",metricOpt,"-tuning",".png",sep = ""), bg = "transparent")
}
#######################To generate the ROC curve of the best model.
bestIndex <- rownames(modelFit$bestTune)[1]
selectedIndices <- modelFit$pred$mtry == modelFit$bestTune[1, "mtry"]
results <- modelFit$results[bestIndex,"ROC"]
g <- ggplot(modelFit$pred[selectedIndices,], aes(m = M, d=factor(obs, levels = c("BT","M")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", results))
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-","ROC-Curve",".png",sep = ""), bg = "transparent")
library(caret)
library(plotROC)
setwd("/media/oscar/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
outputFolder <- "results/"
#Not available in Windows
# library(doMC)
# registerDoMC(cores = 5)
## All subsequent models are then run in parallel
mydata <- read.csv("GrassoControlvsPT.csv")
algorithm <- "rf"
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
set.seed(123)
# we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="LOOCV", classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE, search = "grid",
summaryFunction = summaryFunction, verboseIter = FALSE)
form <- as.formula(paste(colnames(mydata)[ncol(mydata)]," ~ ."))
#execute the algorithms
modelFit <- train(form, data = mydata,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 10,
trControl = fitControl)
#Saving all the results
write.table(modelFit$results, file= paste(outputFolder,"results-", algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = TRUE, na = "")
#Saving the variable importance
varImportance <- varImp(modelFit, scale= TRUE)
write.table(varImportance$importance, file= paste(outputFolder,"varImportance-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
# To save the model to disk
saveRDS(modelFit, paste(outputFolder,"modelfit-",algorithm, ".rds", sep = ""))
# To save which predictors were used in the final model.
write.table(data.frame(Predictor = predictors(modelFit)), file= paste(outputFolder,"predictors-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = FALSE, na = "")
#Only plot the graph for those model that contain tunning process
if(nrow(modelFit$results)>1){
ggplot(modelFit)
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-",metricOpt,"-tuning",".png",sep = ""), bg = "transparent")
}
#######################To generate the ROC curve of the best model.
bestIndex <- rownames(modelFit$bestTune)[1]
selectedIndices <- modelFit$pred$mtry == modelFit$bestTune[1, "mtry"]
results <- modelFit$results[bestIndex,"ROC"]
g <- ggplot(modelFit$pred[selectedIndices,], aes(m = PT, d=factor(obs, levels = c("BT","PT")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", results))
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-","ROC-Curve",".png",sep = ""), bg = "transparent")
modelFit$finalModel
library(caret)
library(plotROC)
setwd("/media/oscar/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
outputFolder <- "results/"
#Not available in Windows
# library(doMC)
# registerDoMC(cores = 5)
## All subsequent models are then run in parallel
mydata <- read.csv("Grasso-ControlesvsM.csv")
algorithm <- "rf"
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
set.seed(123)
# we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="LOOCV", classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE, search = "grid",
summaryFunction = summaryFunction, verboseIter = FALSE)
form <- as.formula(paste(colnames(mydata)[ncol(mydata)]," ~ ."))
#execute the algorithms
modelFit <- train(form, data = mydata,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 10,
trControl = fitControl)
#Saving all the results
write.table(modelFit$results, file= paste(outputFolder,"results-", algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = TRUE, na = "")
#Saving the variable importance
varImportance <- varImp(modelFit, scale= TRUE)
write.table(varImportance$importance, file= paste(outputFolder,"varImportance-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
# To save the model to disk
saveRDS(modelFit, paste(outputFolder,"modelfit-",algorithm, ".rds", sep = ""))
# To save which predictors were used in the final model.
write.table(data.frame(Predictor = predictors(modelFit)), file= paste(outputFolder,"predictors-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = FALSE, na = "")
#Only plot the graph for those model that contain tunning process
if(nrow(modelFit$results)>1){
ggplot(modelFit)
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-",metricOpt,"-tuning",".png",sep = ""), bg = "transparent")
}
#######################To generate the ROC curve of the best model.
bestIndex <- rownames(modelFit$bestTune)[1]
selectedIndices <- modelFit$pred$mtry == modelFit$bestTune[1, "mtry"]
results <- modelFit$results[bestIndex,"ROC"]
g <- ggplot(modelFit$pred[selectedIndices,], aes(m = M, d=factor(obs, levels = c("BT","M")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", results))
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-","ROC-Curve",".png",sep = ""), bg = "transparent")
modelFit$finalModel
library(caret)
library(plotROC)
setwd("/media/oscar/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
outputFolder <- "results/"
#Not available in Windows
# library(doMC)
# registerDoMC(cores = 5)
## All subsequent models are then run in parallel
mydata <- read.csv("GrassoControlvsTumor.csv")
algorithm <- "rf"
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
set.seed(123)
# we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="LOOCV", classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE, search = "grid",
summaryFunction = summaryFunction, verboseIter = FALSE)
form <- as.formula(paste(colnames(mydata)[ncol(mydata)]," ~ ."))
#execute the algorithms
modelFit <- train(form, data = mydata,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 10,
trControl = fitControl)
#Saving all the results
write.table(modelFit$results, file= paste(outputFolder,"results-", algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = TRUE, na = "")
#Saving the variable importance
varImportance <- varImp(modelFit, scale= TRUE)
write.table(varImportance$importance, file= paste(outputFolder,"varImportance-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
# To save the model to disk
saveRDS(modelFit, paste(outputFolder,"modelfit-",algorithm, ".rds", sep = ""))
# To save which predictors were used in the final model.
write.table(data.frame(Predictor = predictors(modelFit)), file= paste(outputFolder,"predictors-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = FALSE, na = "")
#Only plot the graph for those model that contain tunning process
if(nrow(modelFit$results)>1){
ggplot(modelFit)
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-",metricOpt,"-tuning",".png",sep = ""), bg = "transparent")
}
#######################To generate the ROC curve of the best model.
bestIndex <- rownames(modelFit$bestTune)[1]
selectedIndices <- modelFit$pred$mtry == modelFit$bestTune[1, "mtry"]
results <- modelFit$results[bestIndex,"ROC"]
g <- ggplot(modelFit$pred[selectedIndices,], aes(m = T, d=factor(obs, levels = c("BT","T")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", results))
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-","ROC-Curve",".png",sep = ""), bg = "transparent")
modelFit$finalModel
library(caret)
library(plotROC)
setwd("/media/oscar/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
outputFolder <- "results/"
#Not available in Windows
# library(doMC)
# registerDoMC(cores = 5)
## All subsequent models are then run in parallel
mydata <- read.csv("GrassovPTvsM.csv")
algorithm <- "rf"
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
set.seed(123)
# we use an automatic grid by means of using the parameter tunelength
# see http://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/
fitControl <- trainControl(method="LOOCV", classProbs = TRUE,
savePredictions = TRUE, allowParallel= TRUE, search = "grid",
summaryFunction = summaryFunction, verboseIter = FALSE)
form <- as.formula(paste(colnames(mydata)[ncol(mydata)]," ~ ."))
#execute the algorithms
modelFit <- train(form, data = mydata,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 10,
trControl = fitControl)
#Saving all the results
write.table(modelFit$results, file= paste(outputFolder,"results-", algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = TRUE, na = "")
#Saving the variable importance
varImportance <- varImp(modelFit, scale= TRUE)
write.table(varImportance$importance, file= paste(outputFolder,"varImportance-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = TRUE, col.names = TRUE, na = "")
# To save the model to disk
saveRDS(modelFit, paste(outputFolder,"modelfit-",algorithm, ".rds", sep = ""))
# To save which predictors were used in the final model.
write.table(data.frame(Predictor = predictors(modelFit)), file= paste(outputFolder,"predictors-",algorithm, ".csv", sep = ""),
quote = FALSE, sep="," , row.names = FALSE, col.names = FALSE, na = "")
#Only plot the graph for those model that contain tunning process
if(nrow(modelFit$results)>1){
ggplot(modelFit)
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-",metricOpt,"-tuning",".png",sep = ""), bg = "transparent")
}
#######################To generate the ROC curve of the best model.
bestIndex <- rownames(modelFit$bestTune)[1]
selectedIndices <- modelFit$pred$mtry == modelFit$bestTune[1, "mtry"]
results <- modelFit$results[bestIndex,"ROC"]
g <- ggplot(modelFit$pred[selectedIndices,], aes(m = PT, d=factor(obs, levels = c("PT","M")))) +
geom_roc(n.cuts=0) + coord_equal() + style_roc()
g + annotate("text", x=0.85, y=0.15, label=paste("AUC =", results))
ggsave(width = 8, height = 5, filename = paste(outputFolder, algorithm,"-","ROC-Curve",".png",sep = ""), bg = "transparent")
modelFit$finalModel
setwd("/media/ogreyesp/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
library(pheatmap)
library(Cairo)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Clinico=c(N = "red", S = "green"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
setwd("/media/ogreyesp/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
#Load the dataset
data <- read.csv("GrassovPTvsM.csv")
output <- "results/PTvsM/Clustering/"
#Load csv with cluster configurations
clusters <- read.csv(paste(output,"HierarchicalClustering.csv",sep=""))
# The threshold value to filter out the clustering configurations
threshold <- 0.9
if(nrow(clusters)!=0){
#for each cluster
for(i in 1:nrow(clusters)){
auc <- clusters[i,"AUC"]
if(auc >= threshold){
atts <- clusters[i,"Atts"]
items <- unlist(strsplit(as.character(atts), " "))
indexes <- match(items,colnames(data))
#construct the dataframe
indexes <- c(indexes,ncol(data))
newData <- data [,indexes]
imgName <- paste(pathOutput,i,sep = "")
PlotHeatMap(data = newData, imgName = imgName, smplDist = clustering_distance_rows,
clstDist = clustering_method)
}
}
}
library(pheatmap)
library(Cairo)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Clinico=c(N = "red", S = "green"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
setwd("/media/ogreyesp/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
#Load the dataset
data <- read.csv("GrassovPTvsM.csv")
output <- "results/PTvsM/Clustering/"
#Load csv with cluster configurations
clusters <- read.csv(paste(output,"HierarchicalClustering.csv",sep=""))
# The threshold value to filter out the clustering configurations
threshold <- 0.9
if(nrow(clusters)!=0){
#for each cluster
for(i in 1:nrow(clusters)){
auc <- clusters[i,"AUC"]
if(auc >= threshold){
atts <- clusters[i,"Atts"]
items <- unlist(strsplit(as.character(atts), " "))
indexes <- match(items,colnames(data))
#construct the dataframe
indexes <- c(indexes,ncol(data))
newData <- data [,indexes]
imgName <- paste(output, i,sep = "")
PlotHeatMap(data = newData, imgName = imgName, smplDist = clustering_distance_rows,
clstDist = clustering_method)
}
}
}
library(pheatmap)
library(Cairo)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Clinico=c(N = "red", S = "green"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
setwd("/media/ogreyesp/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
#Load the dataset
data <- read.csv("GrassovPTvsM.csv")
output <- "results/PTvsM/Clustering/"
#Load csv with cluster configurations
clusters <- read.csv(paste(output,"HierarchicalClustering.csv",sep=""))
# The threshold value to filter out the clustering configurations
threshold <- 0.9
if(nrow(clusters)!=0){
#for each cluster
for(i in 1:nrow(clusters)){
auc <- clusters[i,"AUC"]
if(auc >= threshold){
atts <- clusters[i,"Atts"]
items <- unlist(strsplit(as.character(atts), " "))
indexes <- match(items,colnames(data))
#construct the dataframe
indexes <- c(indexes,ncol(data))
newData <- data [,indexes]
imgName <- paste(output, i,sep = "")
PlotHeatMap(data = newData, imgName = imgName)
}
}
}
PlotHeatMap(data = data, imgName = "results/mio")
library(pheatmap)
library(Cairo)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Clinico=c(N = "red", S = "green"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
setwd("/media/ogreyesp/DATA/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v5/")
#Load the dataset
data <- read.csv("Grasso-ControlesvsM.csv")
output <- "results/ControlesvsM/Clustering/"
#Load csv with cluster configurations
clusters <- read.csv(paste(output,"HierarchicalClustering.csv",sep=""))
# The threshold value to filter out the clustering configurations
threshold <- 0.9
if(nrow(clusters)!=0){
#for each cluster
for(i in 1:nrow(clusters)){
auc <- clusters[i,"AUC"]
if(auc >= threshold){
atts <- clusters[i,"Atts"]
items <- unlist(strsplit(as.character(atts), " "))
indexes <- match(items,colnames(data))
#construct the dataframe
indexes <- c(indexes,ncol(data))
newData <- data [,indexes]
imgName <- paste(output, i,sep = "")
PlotHeatMap(data = newData, imgName = imgName)
}
}
}
