nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
numberClasses <- length(levels(dataset[,ncol(dataset)]))
#execute the algorithms
for(method in methods){
outputTemp <- paste0(output, "Clustering/",method, "/", fileName,"/")
if(!dir.exists(outputTemp)){
dir.create(outputTemp, recursive = TRUE)
}
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), purity=c(0))
df <- df[-1,]
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
purityGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- as.data.frame(dataset[, listFeatures])
colnames(subdataset) <- colnames(dataset)[listFeatures]
#pass this subdataset to the clustering algorithm
clustering <- hclust(dist(subdataset), method = method)
clustering.cut <- cutree(clustering, numberClasses)
# compute purity
purity <- ClusterPurity(clustering.cut, dataset$Class)
#register the model
if(purity >= threshold){
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(colnames(subdataset)),
Atts= paste(colnames(subdataset), collapse = ' '),
purity=purity))
if(ncol(subdataset)>1){
PlotHeatMap(data = dataset[,c(colnames(subdataset),"Class")], imgName = paste0(outputTemp, "HeatMap-", nrow(df)), clstDist = method)
}
}
if(purityGlobal < purity){
purityGlobal <- purity
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#############End of search by ranking
#order the rows of the dataframe
df <- df[order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= paste0(outputTemp, method,".csv"), quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
}
library(caret)
#Libreria para calcular la pureza y la entropia
library(IntNMF)
library(pheatmap)
library(Cairo)
library(caret)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
#rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Tumor=c(N = "red", T = "green"))
ann_colors = list(Tumor=c(N = "red", T = "green", L="blue"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
determineIndex <-function(a) {
indexes <- which(a==max(a))
return (indexes[1])
}
datasets <- c("parafinas-withoutMissingValues")
#Establecemos los metodos a probar
methods <- c("single",
"complete",
"average",
"mcquitty",
"ward.D",
"ward.D2",
"centroid",
"median")
threshold <- 0.7
output <- "results/"
for(fileName in datasets){
#load the dataset and ranking of features
dataset <-  read.csv(paste(fileName,".csv",sep = ""), sep = ",")
methodsPre <- c("zv","nzv","YeoJohnson","center","scale")
preProcValues <- preProcess(dataset, method = methodsPre)
dataset <- predict(preProcValues, dataset)
rankingFeature <- read.csv(paste0(output, fileName,"-sortedfeatures.csv"), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
numberClasses <- length(levels(dataset[,ncol(dataset)]))
#execute the algorithms
for(method in methods){
outputTemp <- paste0(output, "Clustering/",method, "/", fileName,"/")
if(!dir.exists(outputTemp)){
dir.create(outputTemp, recursive = TRUE)
}
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), purity=c(0))
df <- df[-1,]
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
purityGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- as.data.frame(dataset[, listFeatures])
colnames(subdataset) <- colnames(dataset)[listFeatures]
#pass this subdataset to the clustering algorithm
clustering <- hclust(dist(subdataset), method = method)
clustering.cut <- cutree(clustering, numberClasses)
# compute purity
purity <- ClusterPurity(clustering.cut, dataset$Class)
#register the model
if(purity >= threshold){
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(colnames(subdataset)),
Atts= paste(colnames(subdataset), collapse = ' '),
purity=purity))
if(ncol(subdataset)>1){
PlotHeatMap(data = dataset[,c(colnames(subdataset),"Class")], imgName = paste0(outputTemp, "HeatMap-", nrow(df)), clstDist = method)
}
}
if(purityGlobal < purity){
purityGlobal <- purity
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#############End of search by ranking
#order the rows of the dataframe
df <- df[order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= paste0(outputTemp, method,".csv"), quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
}
#Libreria para calcular la pureza y la entropia
library(IntNMF)
library(pheatmap)
library(Cairo)
library(caret)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
#rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Tumor=c(N = "red", T = "green"))
ann_colors = list(Tumor=c(N = "red", T = "green", L="blue"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
determineIndex <-function(a) {
indexes <- which(a==max(a))
return (indexes[1])
}
datasets <- c("parafinas-withoutMissingValues")
#Establecemos los metodos a probar
methods <- c("single",
"complete",
"average",
"mcquitty",
"ward.D",
"ward.D2",
"centroid",
"median")
threshold <- 0.7
output <- "results/"
for(fileName in datasets){
#load the dataset and ranking of features
dataset <-  read.csv(paste(fileName,".csv",sep = ""), sep = ",")
methodsPre <- c("YeoJohnson","center","scale")
preProcValues <- preProcess(dataset, method = methodsPre)
dataset <- predict(preProcValues, dataset)
rankingFeature <- read.csv(paste0(output, fileName,"-sortedfeatures.csv"), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
numberClasses <- length(levels(dataset[,ncol(dataset)]))
#execute the algorithms
for(method in methods){
outputTemp <- paste0(output, "Clustering/",method, "/", fileName,"/")
if(!dir.exists(outputTemp)){
dir.create(outputTemp, recursive = TRUE)
}
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), purity=c(0))
df <- df[-1,]
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
purityGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- as.data.frame(dataset[, listFeatures])
colnames(subdataset) <- colnames(dataset)[listFeatures]
#pass this subdataset to the clustering algorithm
clustering <- hclust(dist(subdataset), method = method)
clustering.cut <- cutree(clustering, numberClasses)
# compute purity
purity <- ClusterPurity(clustering.cut, dataset$Class)
#register the model
if(purity >= threshold){
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(colnames(subdataset)),
Atts= paste(colnames(subdataset), collapse = ' '),
purity=purity))
if(ncol(subdataset)>1){
PlotHeatMap(data = dataset[,c(colnames(subdataset),"Class")], imgName = paste0(outputTemp, "HeatMap-", nrow(df)), clstDist = method)
}
}
if(purityGlobal < purity){
purityGlobal <- purity
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#############End of search by ranking
#order the rows of the dataframe
df <- df[order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= paste0(outputTemp, method,".csv"), quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
}
#Libreria para calcular la pureza y la entropia
library(IntNMF)
library(pheatmap)
library(Cairo)
library(caret)
PlotHeatMap<-function(data, imgName="HeatMap", format="png", smplDist= "euclidean",
clstDist= "ward.D", viewOpt="detail", rowV=TRUE, colV=TRUE, border=TRUE){
classes <- data[ncol(data)]
data <- data[-ncol(data)]
colnames(data)<-substr(colnames(data),1,18) # some names are too long
#rownames(data) <- 1:nrow(data)
rownames(classes) <- rownames(data)
#Set the name of image
imgName <- paste(imgName, ".", format, sep="")
minW <- 630;
myW <- nrow(data)*18 + 150;
if(myW < minW){
myW <- minW;
}
w <- round(myW/72,2);
myH <- ncol(data)*18 + 150;
h <- round(myH/72,2);
if(border){
border.col<-"grey60";
}else{
border.col <- NA;
}
Cairo(file = imgName, unit="in", dpi=72, width=w, height=h, type=format, bg="white");
# Specify colors
ann_colors = list(Tumor=c(N = "red", T = "green"))
ann_colors = list(Tumor=c(N = "red", T = "green", L="blue"))
pheatmap(t(data),fontsize=8, fontsize_row=8, clustering_distance_rows = smplDist,
clustering_distance_cols = smplDist, clustering_method = clstDist,
border_color = border.col, cluster_rows = colV,
cluster_cols = rowV, annotation_col=classes, annotation_colors = ann_colors)
dev.off()
}
determineIndex <-function(a) {
indexes <- which(a==max(a))
return (indexes[1])
}
datasets <- c("parafinas-withoutMissingValues")
#Establecemos los metodos a probar
methods <- c("single",
"complete",
"average",
"mcquitty",
"ward.D",
"ward.D2",
"centroid",
"median")
threshold <- 0.7
output <- "results/"
for(fileName in datasets){
#load the dataset and ranking of features
dataset <-  read.csv(paste(fileName,".csv",sep = ""), sep = ",")
methodsPre <- c("zv","nzv","YeoJohnson","center","scale")
preProcValues <- preProcess(dataset, method = methodsPre)
dataset <- predict(preProcValues, dataset)
rankingFeature <- read.csv(paste0(output, fileName,"-sortedfeatures.csv"), sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
numberClasses <- length(levels(dataset[,ncol(dataset)]))
#execute the algorithms
for(method in methods){
outputTemp <- paste0(output, "Clustering/",method, "/", fileName,"/")
if(!dir.exists(outputTemp)){
dir.create(outputTemp, recursive = TRUE)
}
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), purity=c(0))
df <- df[-1,]
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
purityGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- as.data.frame(dataset[, listFeatures])
colnames(subdataset) <- colnames(dataset)[listFeatures]
#pass this subdataset to the clustering algorithm
clustering <- hclust(dist(subdataset), method = method)
clustering.cut <- cutree(clustering, numberClasses)
# compute purity
purity <- ClusterPurity(clustering.cut, dataset$Class)
#register the model
if(purity >= threshold){
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(colnames(subdataset)),
Atts= paste(colnames(subdataset), collapse = ' '),
purity=purity))
if(ncol(subdataset)>1){
#PlotHeatMap(data = dataset[,c(colnames(subdataset),"Class")], imgName = paste0(outputTemp, "HeatMap-", nrow(df)), clstDist = method)
}
}
if(purityGlobal < purity){
purityGlobal <- purity
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#############End of search by ranking
#order the rows of the dataframe
df <- df[order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= paste0(outputTemp, method,".csv"), quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
}
install.packages("FactoMineR")
View(dataset)
View(dataset)
View(dataset)
View(dataset)
View(dataset)
write.csv(dataset, file = "preproc.csv", row.names = T, col.names = T, quote = F, sep = ",")
library(FactoMineR)
library(factoextra)
install.packages("factoextra")
install.packages("FactoInvestigate")
install.packages("Factoshiny")
install.packages("missMDA")
library(FactoMineR)
library(factoextra)
library(FactoInvestigate)
library(Factoshiny)
library(missMDA)
dataset <- read.csv("parafinas-withoutMissingValues-preproc.csv", na.strings = "", row.names = 1)
dataset <- read.csv("parafinas-withoutMissingValues-preproc.csv", na.strings = "", row.names = 1)
View(dataset)
?PCA
#PCA with supplementary variables
res <- PCA(dataset,
scale.unit = FALSE,
quali.sup = c(ncol(dataset)),
graph = FALSE)
res
Investigate(res, document = "word_document", file = "Investigate-Prostata.Rmd")
summary(res, nbelements = Inf)
# Contributions of variables to PC1
fviz_contrib(res, choice = "var", axes = 2, top = 10)
#screeplot
fviz_screeplot(res, addlabels = TRUE)
#Decription of the dimensios
dimdesc(res)
#screeplot
fviz_screeplot(res, addlabels = TRUE)
# Graph of variables
fviz_pca_var(res, geom = c("point", "text"), repel = TRUE, col.var = "contrib", labelsize = 4)
# Graph of variables
fviz_pca_var(res, geom = c("point", "text"), repel = TRUE, col.var = "contrib", labelsize = 4)
# Contributions of variables to PC1
fviz_contrib(res, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC1
fviz_contrib(res, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC1
fviz_contrib(res, choice = "var", axes = 1, top = 26)
# Graph of individuals
# 1. Use repel = TRUE to avoid overplotting
# 2. Control automatically the color of individuals using the cos2
# cos2 = the quality of the individuals on the factor map
# Use points only
# 3. Use gradient color
fviz_pca_ind(res, col.ind = "contrib",
repel = TRUE # Avoid text overlapping (slow if many points)
)
# Biplot of individuals and variables
fviz_pca_biplot(res, repel = TRUE)
plot(res, cex=0.5, habillage= "Diabetes", invisible = "quali", axes=c(1,2))
plot(res, cex=0.5, habillage= "Diabetes", invisible = "quali", axes=c(1,2))
plot(res, cex=0.5, habillage= "Class", invisible = "quali", axes=c(1,2))
plot(res, cex=0.5, choix="var", title="Variable PCA graph", axes=c(1,2), autoLab = "yes")
plotellipses(res, cex = 0.5, keepvar=5)
PCAshiny(dataset)
HCPCshiny(dataset)
PCAshiny(dataset)
# Graph of individuals
# 1. Use repel = TRUE to avoid overplotting
# 2. Control automatically the color of individuals using the cos2
# cos2 = the quality of the individuals on the factor map
# Use points only
# 3. Use gradient color
fviz_pca_ind(res, col.ind = "contrib",
repel = TRUE # Avoid text overlapping (slow if many points)
)
# Biplot of individuals and variables
fviz_pca_biplot(res, repel = TRUE)
summary(res, nbelements = Inf)
#Decription of the dimensios
dimdesc(res)
#screeplot
fviz_screeplot(res, addlabels = TRUE)
#Decription of the dimensios
dimdesc(res)
#screeplot
fviz_screeplot(res, addlabels = TRUE)
# Graph of variables
fviz_pca_var(res, geom = c("point", "text"), repel = TRUE, col.var = "contrib", labelsize = 4)
# Contributions of variables to PC1
fviz_contrib(res, choice = "var", axes = 1, top = 26)
