df
rbind()
?rbind
rbind(df,df)
rbind(df,c(NumberAtts=3, Atts="sfkdlggdg", AUC=0.98))
df <- rbind(df,c(NumberAtts=3, Atts="sfkdlggdg", AUC=0.98))
df
df <- data.frame(matrix(ncol = 3, nrow = 0))
df[nrow(df) + 1,] = c("v1","v2","aaaa")
df
df <- data.frame(matrix(ncol = 3, nrow = 0))
colnames(df) <- c("NumberAtts", "Atts", "AUC")
df[nrow(df) + 1,] = c("v1","v2","aaaa")
df
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v3/")
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v3/")
threshold <- 0.85
output <- "results/"
dataset <-  read.csv("NuestraCohorteZscore-sortedfeatures.csv")
View(dataset)
rankingFeature <- read.csv("NuestraCohorteZscore-sortedfeatures.csv")
dataset <-  read.csv("NuestraCohorteZscore.csv")
View(dataset)
rankingFeature <- read.csv("NuestraCohorteZscore-sortedfeatures.csv", sep = "\t")
View(rankingFeature)
rankingFeature <- read.csv("NuestraCohorteZscore-sortedfeatures.csv", sep = "\t")
View(rankingFeature)
nFeatures <- nrow(rankingFeature)
nFeatures
classIndex <- ncol(dataset)
classIndex
algorithmsAbleMulti <- c("AdaBoost.M1", "AdaBag", "bagFDA", "bagEarth", "LogitBoost", "J48", "C5.0", "cforest",
"ctree", "xgbLinear", "xgbTree", "fda", "glmnet",
"LMT", "msaenet", "earth", "pam",
"RRF", "JRip", "PART", "OneR", "sdwd", "sparseLDA", "gbm", "wsrf")
algorithmsTwoClassesOnly <- c("adaboost", "bartMachine", "ada", "gamboost", "glmStepAIC",
"nodeHarvest")
numberClasses <- length(levels(dataset[,ncol(dataset)]))
algorithms <- algorithmsAbleMulti
metricOpt <- "AUC"
summaryFunction <- multiClassSummary
if(numberClasses == 2)
{
algorithms <- c(algorithms, algorithmsTwoClassesOnly)
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
}
algorithms
metricOpt
summaryFunction()
summaryFunction
metricOpt
set.seed(123)
form <- as.formula(paste(colnames(mydata)[ncol(mydata)]," ~ ."))
form <- as.formula(paste(colnames(mydata)[ncol(dataset)]," ~ ."))
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
form
fitControl <- trainControl(method="adaptive_cv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, search="random", allowParallel= TRUE,
summaryFunction = summaryFunction, verboseIter = FALSE,
adaptive = list(min = 10, alpha = 0.05, method = "BT", complete = TRUE))
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
listFeatures
classIndex
View(subdataset)
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
listFeatures
View(subdataset)
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
install.packages(BradleyTerry2)
install.packages("BradleyTerry2")
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
n
?trainControl
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
bestTuneIndex
modelFit$bestTune
rownames(modelFit$bestTune)
rownames(modelFit$bestTune)[1]
rownames(modelFit$besTune)[1]
bestTuneIndex
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
bestTuneIndex
modelFit$results
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
modelFit$results
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
modelFit$results
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
auc
otherFeature
feature
listFeatures
modelFit$results
vars
df
class(vars)
paste(vars," ")
vars
paste(vars," ")
class(vars)
vars
paste(vars,sep = " ")
unlist(vars)
as.factor(vars)
paste(as.factor(vars),"")
paste(as.factor(vars),sep = "")
paste(as.factor(vars),sep = "", collapse = NULL)
paste(as.factor(vars),sep = "", collapse = TRUE)
vars
class(vars)
vars
length(vars)
paste(vars, collapse = '')
paste(vars,, sep = " ", collapse = '')
paste(vars, sep = " ", collapse = '')
paste(vars, sep = " ", collapse = ' ')
paste(vars, collapse = ' ')
debugSource('D:/OneDrive - Universidad de Córdoba/workspace/Rprojects/SearchBasedRankingFeatures.R')
View(subdataset)
df
View(subdataset)
listFeatures
listFeatures
View(subdataset)
df
df <- df[ order(-df[, metricOpt]), ]
df <- df[ order(-metricOpt), ]
metricOpt
df
df <- df[ order(-metricOpt), ]
df <- df[ order(-df[, metricOpt]), ]
-df[, metricOpt]
df[, metricOpt]
class(df[, metricOpt])
lapply(df, class)
class(df$ID) <- numeric
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df[1,] <- c(0, 0, "", 0)
lapply(df, class)
df
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df[1,] <- c(numeric(0), numeric(0), "", numeric(0))
lapply(df, class)
df[, 1:2] <- sapply(df[, 1:2], as.numeric)
df[, c(1:2,4)] <- sapply(df[, 1:2], as.numeric)
c(1:2)
c(1:2,4)
df[, c(1:2,4)] <- sapply(df[, 1:2,4], as.numeric)
df <- data.frame(matrix(ncol = 4, nrow = 0))
df[, c(1:2,4)] <- sapply(df[, 1:2,4], as.numeric)
lapply(df,class)
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df[, c(1:2,4)] <- sapply(df[, 1:2,4], as.numeric)
df[, 3] <- sapply(df[, 3], as.character)
lapply(df,class)
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df
df[, c(1:2,4)] <- sapply(df[, 1:2,4], as.numeric)
df
df[, 3] <- sapply(df[, 3], as.character)
df
?data.frame
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df[, c(1:2,4)] <- sapply(df[, 1:2,4], as.numeric)
df
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df[, c(1:2,4)] <- sapply(df[, 1:2,4], as.numeric)
df
df$Atts
df[,3]
df[,4]
df[, 3] <- sapply(df[, 3], as.character)
df[,4]
df[,3]
df <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(df) <- c("ID","NumberAtts", "Atts", metricOpt)
df[, 3] <- sapply(df[, 3], as.character)
df
df <- data.frame("ID","NumberAtts", "Atts", metricOpt)
df
df <- data.frame(ID, NumberAtts, Atts, metricOpt)
df <- data.frame(ID, NumberAtts, Atts, metricOpt)
df <- data.frame(IDs, NumberAtts, Atts, metricOpt)
df <- data.frame(IDs = c(0), NumberAtts=c(0), Atts=c("dd"), metricOpt=c(0))
df
lapply(df,class)
df[1,] <- NULL
df[1,] <- NULL
df <- data.frame(IDs = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
lapply(df,class)
df
df
df <- df[-1,]
df
df <- df[ order(-df[, metricOpt]), ]
df <- data.frame(IDs = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
df <- df[ order(-df[, metricOpt]), ]
df <- df[ order(-df[, 4]), ]
df
metricOpt
library(caret)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v3/")
threshold <- 0.85
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("NuestraCohorteZscore.csv")
rankingFeature <- read.csv("NuestraCohorteZscore-sortedfeatures.csv", sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
algorithmsAbleMulti <- c("AdaBoost.M1", "AdaBag", "bagFDA", "bagEarth", "LogitBoost", "J48", "C5.0", "cforest",
"ctree", "xgbLinear", "xgbTree", "fda", "glmnet",
"LMT", "msaenet", "earth", "pam",
"JRip", "PART", "rf", "RRF", "OneR", "sdwd", "sparseLDA", "gbm", "wsrf")
algorithmsTwoClassesOnly <- c("adaboost", "bartMachine", "ada", "gamboost", "glmStepAIC",
"nodeHarvest")
numberClasses <- length(levels(dataset[,ncol(dataset)]))
algorithms <- algorithmsAbleMulti
metricOpt <- "AUC"
summaryFunction <- multiClassSummary
if(numberClasses == 2)
{
algorithms <- c(algorithms, algorithmsTwoClassesOnly)
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
}
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, search="random", allowParallel= TRUE,
summaryFunction = summaryFunction, verboseIter = FALSE)
#execute the algorithms
for(algorithm in algorithms){
#The dataframe where we stored the results for this algorithm
df <- data.frame(IDs = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,algorithm,".csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
#We evaluate a maximum of 100 combinations of different parameter values
modelFit <- train(form, data = subdataset,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 50,
trControl = fitControl)
bestTuneIndex <- as.numeric(rownames(modelFit$bestTune)[1])
auc <- modelFit$results[bestTuneIndex, metricOpt]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df[nrow(df) + 1,] = c(nrow(df) + 1, length(vars), paste(vars, collapse = ' '), auc)
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-",algorithm,"-", nrow(df),".rds", sep = ""))
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[, ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
library(caret)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v3/")
threshold <- 0.85
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("NuestraCohorteZscore.csv")
rankingFeature <- read.csv("NuestraCohorteZscore-sortedfeatures.csv", sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
algorithmsAbleMulti <- c("rf", "AdaBoost.M1", "AdaBag", "bagFDA", "bagEarth", "LogitBoost", "J48", "C5.0", "cforest",
"ctree", "xgbLinear", "xgbTree", "fda", "glmnet",
"LMT", "msaenet", "earth", "pam",
"JRip", "PART", "RRF", "OneR", "sdwd", "sparseLDA", "gbm", "wsrf")
algorithmsTwoClassesOnly <- c("adaboost", "bartMachine", "ada", "gamboost", "glmStepAIC",
"nodeHarvest")
numberClasses <- length(levels(dataset[,ncol(dataset)]))
algorithms <- algorithmsAbleMulti
metricOpt <- "AUC"
summaryFunction <- multiClassSummary
if(numberClasses == 2)
{
algorithms <- c(algorithms, algorithmsTwoClassesOnly)
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
}
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, search="random", allowParallel= TRUE,
summaryFunction = summaryFunction, verboseIter = FALSE)
#execute the algorithms
for(algorithm in algorithms){
#The dataframe where we stored the results for this algorithm
df <- data.frame(IDs = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,algorithm,".csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
#We evaluate a maximum of 50 combinations of different parameter values
modelFit <- train(form, data = subdataset,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 50,
trControl = fitControl)
bestTuneIndex <- as.numeric(rownames(modelFit$bestTune)[1])
auc <- modelFit$results[bestTuneIndex, metricOpt]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df[nrow(df) + 1,] = c(nrow(df) + 1, length(vars), paste(vars, collapse = ' '), auc)
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-",algorithm,"-", nrow(df),".rds", sep = ""))
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[, ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
df
df <- df[ order(-"ROC"), ]
df
vars
paste(vars, collapse = ' ')
c(nrow(df) + 1, length(vars), paste(vars, collapse = ' '), auc)
lapply(df,class)
df <- data.frame(IDs = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
df
lapply(df,class)
rbind(df,data.frame(IDs = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0)))
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
df
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc)
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-",algorithm,"-", nrow(df),".rds", sep = ""))
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
df
lapply(df,class)
df <- df[ order(-df[,ncol(df)]), ]
df
df
library(caret)
setwd("D:/OneDrive - Universidad de Córdoba/workspace/IMIBIC/datasets/cancer/v3/")
threshold <- 0.85
output <- "results/"
#load the dataset and ranking of features
dataset <-  read.csv("NuestraCohorteZscore.csv")
rankingFeature <- read.csv("NuestraCohorteZscore-sortedfeatures.csv", sep = "\t")
nFeatures <- nrow(rankingFeature)
classIndex <- ncol(dataset)
algorithmsAbleMulti <- c("rf", "AdaBoost.M1", "AdaBag", "bagFDA", "bagEarth", "LogitBoost", "J48", "C5.0", "cforest",
"ctree", "xgbLinear", "xgbTree", "fda", "glmnet",
"LMT", "msaenet", "earth", "pam",
"JRip", "PART", "RRF", "OneR", "sdwd", "sparseLDA", "gbm", "wsrf")
algorithmsTwoClassesOnly <- c("adaboost", "bartMachine", "ada", "gamboost", "glmStepAIC",
"nodeHarvest")
numberClasses <- length(levels(dataset[,ncol(dataset)]))
algorithms <- algorithmsAbleMulti
metricOpt <- "AUC"
summaryFunction <- multiClassSummary
if(numberClasses == 2)
{
algorithms <- c(algorithms, algorithmsTwoClassesOnly)
metricOpt <- "ROC"
summaryFunction <- twoClassSummary
}
set.seed(123)
form <- as.formula(paste(colnames(dataset)[ncol(dataset)]," ~ ."))
fitControl <- trainControl(method="repeatedcv", number = 10,
repeats = 3, classProbs = TRUE,
savePredictions = TRUE, search="random", allowParallel= TRUE,
summaryFunction = summaryFunction, verboseIter = FALSE)
#execute the algorithms
for(algorithm in algorithms){
#The dataframe where we stored the results for this algorithm
df <- data.frame(ID = c(0), NumberAtts=c(0), Atts=c(" "), metricOpt=c(0))
df <- df[-1,]
fileName <- paste(output,algorithm,".csv")
#Execute the search by ranking of features
#######################
#All features will be considered as pivot one time
for(feature in 1:nFeatures){
pivotFeature <- rankingFeature[feature,"Index"]
listFeatures <- c(pivotFeature)
aucGlobal <- -1
for(otherFeature in feature:nFeatures)
{
# The last case
if(otherFeature != feature)
{
listFeatures <- c(listFeatures, rankingFeature[otherFeature,"Index"])
}
#extract the subset
subdataset <- dataset[, c(listFeatures, classIndex)]
#pass this subdataset to the classification algorithm
#We evaluate a maximum of 50 combinations of different parameter values
modelFit <- train(form, data = subdataset,
method=algorithm,
metric = metricOpt,
maximize = TRUE,
tuneLength = 5,
trControl = fitControl)
bestTuneIndex <- as.numeric(rownames(modelFit$bestTune)[1])
auc <- modelFit$results[bestTuneIndex, metricOpt]
#register the model
if(auc>= threshold){
vars <- predictors(modelFit)
df <- rbind(df, data.frame(ID = nrow(df) + 1, NumberAtts= length(vars), Atts= paste(vars, collapse = ' '), metricOpt=auc))
#Saving the model for graphing plots a posteriory if it is necessary
saveRDS(modelFit, paste(output,"modelfit-",algorithm,"-", nrow(df),".rds", sep = ""))
}
if(aucGlobal < auc){
aucGlobal <- auc
}
else{
#remove the last feature added. due to did not apport any advantage
listFeatures <- listFeatures[1:(length(listFeatures)-1)]
}
}
}
#######################End of search by ranking
#order the rows of the dataframe
df <- df[ order(-df[,ncol(df)]), ]
#save the dataframe
write.table(df, file= fileName, quote = FALSE, sep="," , row.names = FALSE,
col.names = TRUE)
}
